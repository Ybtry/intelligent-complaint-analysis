{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josib\\Documents\\intelligent-complaint-analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Task 3: Building the RAG Core Logic and Evaluation\n",
      "Loaded FAISS index with 65322 embeddings.\n",
      "Loaded metadata for 65322 chunks.\n",
      "Loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Re-creating text chunks for content retrieval...\n",
      "Re-created 82236 text chunks for retrieval.\n",
      "Loading LLM: distilgpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 'distilgpt2' loaded successfully on CPU.\n",
      "\n",
      "--- Qualitative Evaluation ---\n",
      "\n",
      "Question 1: What are common complaints about credit cards?\n",
      "Generated Answer: 1) customer support is required in this case i would have to file a formal complaint to get my card refund for a refund. 2) i can take an action to provide my customer with an account at credis as time has come to an end and can only take one day to contact me for help. 3) the customer is entitled to help in contacting me with any issues that make me feel like I have lost my life i tried to leave the business so i could have a better life. 4) he is responsible for how i get paid i am not responsible of how I pay for my service due i are not entitled as he has the right to not need a check i was told i cannot use my credit to pay again so he can have better insurance and that is why i got paid to him without the help of a bank. 5) his personal debt is a big problem as credit is very expensive in many parts of America with the cost of living being higher due in large part\n",
      "Retrieved Sources (Top 2):\n",
      "  Source 1 (Product: Money transfer, virtual currency, or money service, Original ID: 15230): i am writing regarding my transaction with xxxxxxxx xxxx xxxx xxxxxxxx on xxxxxxxx with a charged of xxxx the two rugs i ordered were supposed to be delivered one week earlier but instead they were se...\n",
      "  Source 2 (Product: Credit card, Original ID: 117646): the dates of the fraudulent charges happened are xxxxxxxx and xxxx the amounts are and respectively i filed claims to xxxx and bank of america and they did not take any action and have been pushing th...\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 2: Why are people unhappy with BNPL services?\n",
      "Generated Answer: bc my customer's website was never able as i had never seen a BNDPL service that was available and i knew that is a bad thing but if you call me you will be able do your best to get a refund after you have read the contract you can get back the deal\n",
      "ask for an explanation of why they charged you for this service so you might find that it doesn\n",
      "you can check out my address to make sure you dont get my email address.\n",
      "Retrieved Sources (Top 2):\n",
      "  Source 1 (Product: Payday loan, title loan, personal loan, or advance loan, Original ID: 434318): i received the bread financial american express credit card provided by comenity capital bank back in xxxxxxxx in general american express is known nationally and worldwide has a good reputation and i...\n",
      "  Source 2 (Product: Money transfer, virtual currency, or money service, Original ID: 446941): paid this company and had them on the phone at the same time my bank had sent the lender a rolling bank statement via fax showing that the payment was made on xxxx at xxxx et and that the payment was ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 3: Are there issues with money transfers related to fraud?\n",
      "Generated Answer: Yes i is still working on a $600-plus loan at xxxxxxxxx xxx that is due for my student loan. I am not sure what is going on but i will update it when i get back to school\n",
      "problem is the money transfer related not the card but that was said by the company that has the issue i now has to contact me\n",
      "question is my account in order to get my bills and I will\n",
      "Retrieved Sources (Top 2):\n",
      "  Source 1 (Product: Checking or savings account, Original ID: 185078): i want to apologize in advance for the length of this summary on xxxx xxxx at approx xxxx this kind of treatment and discrimination is sick i ordered a xxxx through xxxx was approved transferred to an...\n",
      "  Source 2 (Product: Checking or savings account, Original ID: 233804): on xxxxxxxx we purchased several items from xxxx xxxx the total was the agreement made at the time of the purchase was that a portion of the purchase was payable without interest over a period of mont...\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 4: What problems are customers facing with savings accounts?\n",
      "Generated Answer: i dont have many banks offering unlimited savings account to customers who are not in banking. I have one debit card that I could use to make a check and I would like to see a bank like that which is not considered an ATM. The bank would have to charge the deposit for all the costs of getting and if I want to buy the cards i would also be in a banking facility and maybe they would be charged the cost of that, maybe their interest will be increased and that would create a problem and it would make more sense for them to not charge interest as they are already paying the full amount.\n",
      "Retrieved Sources (Top 2):\n",
      "  Source 1 (Product: Checking or savings account, Original ID: 82704): opened by the thief i only have a few accounts with citibank and these are lines of credit i do not have any credit cards with citibank and i did not submit multiple applications yet any time i do act...\n",
      "  Source 2 (Product: Checking or savings account, Original ID: 451582): if they can request the check back but i keep getting the run around from xxxx xxxx as well a citi bank...\n",
      "--------------------------------------------------\n",
      "\n",
      "Question 5: Tell me about complaints regarding personal loans.\n",
      "Generated Answer: Your account has a credit balance that's not required but this means you have a bank that has one of these credit cards. if you can't get them to give you a name please tell me I will tell you what i think. i know\n",
      "Retrieved Sources (Top 2):\n",
      "  Source 1 (Product: Money transfer, virtual currency, or money service, Original ID: 69433): xxxx xxxx via td bank does not allow payments other than the minimum amount through their automated payment system this forces anyone who only pays through this system to pay interest at the end of a ...\n",
      "  Source 2 (Product: Payday loan, title loan, personal loan, or advance loan, Original ID: 75972): has since been closed i have proof of this account and provided to chase but they say they can not find the account since it is no longer active proof of the account was provided and i still have to s...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 187\u001b[39m\n\u001b[32m    177\u001b[39m     sources_formatted = \u001b[33m\"\u001b[39m\u001b[33m<br>\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m result[\u001b[33m\"\u001b[39m\u001b[33mRetrieved Sources\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m2\u001b[39m]])\n\u001b[32m    179\u001b[39m     markdown_table += (\n\u001b[32m    180\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mQuestion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_answer_formatted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mComments/Analysis\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m |\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m report_path = os.path.join(os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m)), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrag_qualitative_evaluation_report.md\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(report_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    189\u001b[39m     f.write(markdown_table)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, set_seed, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"Starting Task 3: Building the RAG Core Logic and Evaluation\")\n",
    "\n",
    "vector_store_dir = '../vector_store/'\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "llm_model_name = 'distilgpt2'\n",
    "input_path = '../data/filtered_complaints.csv'\n",
    "sample_size = 50000\n",
    "\n",
    "try:\n",
    "    faiss_index_path = os.path.join(vector_store_dir, 'faiss_index.bin')\n",
    "    metadata_path = os.path.join(vector_store_dir, 'metadata.pkl')\n",
    "\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "    print(f\"Loaded FAISS index with {index.ntotal} embeddings.\")\n",
    "\n",
    "    with open(metadata_path, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    print(f\"Loaded metadata for {len(metadata)} chunks.\")\n",
    "\n",
    "    embedding_model = SentenceTransformer(embedding_model_name)\n",
    "    print(f\"Loaded embedding model: {embedding_model_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Required FAISS index or metadata files not found.\")\n",
    "    print(f\"Please ensure Task 2 completed successfully and check '{vector_store_dir}' directory.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Re-creating text chunks for content retrieval...\")\n",
    "try:\n",
    "    df_original = pd.read_csv(input_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {input_path} not found. Please ensure Task 1 completed successfully.\")\n",
    "    exit()\n",
    "\n",
    "df_original['cleaned_narrative'] = df_original['cleaned_narrative'].astype(str).fillna('')\n",
    "df_original = df_original[df_original['cleaned_narrative'].str.strip() != '']\n",
    "\n",
    "if len(df_original) > sample_size:\n",
    "    df_original = df_original.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    df_original = df_original.reset_index(drop=True)\n",
    "\n",
    "text_splitter_local = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "all_chunks_text = []\n",
    "for idx, row in df_original.iterrows():\n",
    "    narrative = row['cleaned_narrative']\n",
    "    current_docs = text_splitter_local.create_documents([narrative])\n",
    "    for doc in current_docs:\n",
    "        all_chunks_text.append(doc.page_content)\n",
    "print(f\"Re-created {len(all_chunks_text)} text chunks for retrieval.\")\n",
    "\n",
    "\n",
    "print(f\"Loading LLM: {llm_model_name}\")\n",
    "device = -1\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_model_name)\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=device)\n",
    "set_seed(42)\n",
    "print(f\"LLM '{llm_model_name}' loaded successfully on {'GPU' if device != -1 else 'CPU'}.\")\n",
    "\n",
    "\n",
    "def retrieve_chunks(query, top_k=5):\n",
    "    query_embedding = embedding_model.encode([query]).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "    \n",
    "    retrieved_chunks_content = []\n",
    "    retrieved_sources_info = []\n",
    "\n",
    "    for i in I[0]:\n",
    "        if 0 <= i < len(all_chunks_text):\n",
    "            chunk_content = all_chunks_text[i]\n",
    "            \n",
    "            chunk_meta = metadata[i]\n",
    "            \n",
    "            retrieved_chunks_content.append(chunk_content)\n",
    "            retrieved_sources_info.append({\n",
    "                'original_id': chunk_meta.get('original_id', 'N/A'),\n",
    "                'product': chunk_meta.get('product', 'N/A'),\n",
    "                'chunk_id': chunk_meta.get('chunk_id', 'N/A'),\n",
    "                'content': chunk_content\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Retrieved index {i} out of bounds for all_chunks_text ({len(all_chunks_text)}). Skipping.\")\n",
    "    return retrieved_chunks_content, retrieved_sources_info\n",
    "\n",
    "prompt_template = \"\"\"You are a financial analyst assistant for CrediTrust. Your task is to answer questions about customer complaints. Use the following retrieved complaint excerpts to formulate your answer. If the context doesn't contain the answer, state that you don't have enough information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "def generate_answer(question, top_k=5):\n",
    "    retrieved_texts, retrieved_sources = retrieve_chunks(question, top_k)\n",
    "    \n",
    "    context = \"\\n\\n\".join(retrieved_texts)\n",
    "    \n",
    "    full_prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    response = generator(\n",
    "        full_prompt,\n",
    "        max_new_tokens=200,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "    \n",
    "    generated_text = response[0]['generated_text']\n",
    "    \n",
    "    answer_start_index = generated_text.lower().find(\"answer:\")\n",
    "    if answer_start_index != -1:\n",
    "        extracted_answer = generated_text[answer_start_index + len(\"answer:\"):].strip()\n",
    "    else:\n",
    "        extracted_answer = generated_text.replace(full_prompt, \"\").strip()\n",
    "    \n",
    "    return extracted_answer, retrieved_sources\n",
    "\n",
    "print(\"\\n--- Qualitative Evaluation ---\")\n",
    "test_questions = [\n",
    "    \"What are common complaints about credit cards?\",\n",
    "    \"Why are people unhappy with BNPL services?\",\n",
    "    \"Are there issues with money transfers related to fraud?\",\n",
    "    \"What problems are customers facing with savings accounts?\",\n",
    "    \"Tell me about complaints regarding personal loans.\"\n",
    "]\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, question in enumerate(test_questions):\n",
    "    print(f\"\\nQuestion {i+1}: {question}\")\n",
    "    answer, sources = generate_answer(question, top_k=5)\n",
    "    print(f\"Generated Answer: {answer}\")\n",
    "    print(\"Retrieved Sources (Top 2):\")\n",
    "    for j, source in enumerate(sources[:2]):\n",
    "        print(f\"  Source {j+1} (Product: {source['product']}, Original ID: {source['original_id']}): {source['content'][:200]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    evaluation_results.append({\n",
    "        \"Question\": question,\n",
    "        \"Generated Answer\": answer,\n",
    "        \"Retrieved Sources\": [\n",
    "            f\"Source {k+1} (Product: {s['product']}, Original ID: {s['original_id']})\" for k, s in enumerate(sources)\n",
    "        ],\n",
    "        \"Quality Score\": \"N/A\",\n",
    "        \"Comments/Analysis\": \" \"\n",
    "    })\n",
    "\n",
    "markdown_table = \"\"\"\n",
    "## Evaluation Table\n",
    "\n",
    "| Question | Generated Answer | Retrieved Sources (Top 2) | Quality Score (1-5) | Comments/Analysis |\n",
    "|---|---|---|---|---|\n",
    "\"\"\"\n",
    "\n",
    "for result in evaluation_results:\n",
    "    cleaned_generated_answer = result['Generated Answer'].replace('\\n', '<br>')\n",
    "    generated_answer_formatted = f\"> {cleaned_generated_answer}\"\n",
    "\n",
    "    sources_formatted = \"<br>\".join([f\"- {s}\" for s in result[\"Retrieved Sources\"][:2]])\n",
    "\n",
    "    markdown_table += (\n",
    "        f\"| {result['Question']} \"\n",
    "        f\"| {generated_answer_formatted} \"\n",
    "        f\"| {sources_formatted} \"\n",
    "        f\"| {result['Quality Score']} \"\n",
    "        f\"| {result['Comments/Analysis']} |\\n\"\n",
    "    )\n",
    "\n",
    "report_path = os.path.join('..', 'data', 'processed', 'rag_qualitative_evaluation_report.md')\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_table)\n",
    "print(f\"\\nQualitative evaluation report saved to: {report_path}\")\n",
    "\n",
    "print(\"Task 3: Building the RAG Core Logic and Evaluation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
